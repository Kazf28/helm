# This file defines all the models officially supported by the Helm API.
# The model names here should match the model names in model_deployments.yaml.

# If you want to add a new model, you can technically do it here but we recommend
# you to do it in private/model_metadatas.yaml instead.

models:

  # =========== AI21 Labs =========== #
  - name: ai21/j1-jumbo
    display_name: J1-Jumbo v1 (178B)
    description: Jurassic-1 Jumbo (178B parameters) ([docs](https://studio.ai21.com/docs/jurassic1-language-models/), [tech report](https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf)).
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 178000000000
    release_date: 2021-08-11
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  - name: ai21/j1-large
    display_name: J1-Large v1 (7.5B)
    description: Jurassic-1 Large (7.5B parameters) ([docs](https://studio.ai21.com/docs/jurassic1-language-models/), [tech report](https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf)).
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 7500000000
    release_date: 2021-08-11
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  - name: ai21/j1-grande
    display_name: J1-Grande v1 (17B)
    description: Jurassic-1 Grande (17B parameters) with a "few tweaks" to the training process ([docs](https://studio.ai21.com/docs/jurassic1-language-models/), [tech report](https://uploads-ssl.webflow.com/60fd4503684b466578c0d307/61138924626a6981ee09caf6_jurassic_tech_paper.pdf)).
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 17000000000
    release_date: 2022-05-03
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  - name: ai21/j1-grande-v2-beta
    display_name: J1-Grande v2 beta (17B)
    description: Jurassic-1 Grande v2 beta (17B parameters)
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 17000000000
    release_date: 2022-10-28
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  - name: ai21/j2-jumbo
    display_name: Jurassic-2 Jumbo (178B)
    description: Jurassic-2 Jumbo (178B parameters) ([docs](https://www.ai21.com/blog/introducing-j2))
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 178000000000
    release_date: 2023-03-09
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  - name: ai21/j2-large
    display_name: Jurassic-2 Large (7.5B)
    description: Jurassic-2 Large (7.5B parameters) ([docs](https://www.ai21.com/blog/introducing-j2))
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 7500000000
    release_date: 2023-03-09
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  - name: ai21/j2-grande
    display_name: Jurassic-2 Grande (17B)
    description: Jurassic-2 Grande (17B parameters) ([docs](https://www.ai21.com/blog/introducing-j2))
    creator_organization_name: AI21 Labs
    access: limited
    num_parameters: 17000000000
    release_date: 2023-03-09
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, AI21_TOKENIZER_TAG]

  # TODO: Add new AI21 models (like ai21/j2-ultra) here.
  # ================================= #



  # =========== Aleph Alpha =========== #
  # Aleph Alpha's Luminous models: https://docs.aleph-alpha.com/docs/introduction/luminous
  # TODO: add Luminous World when it's released
  - name: AlephAlpha/luminous-base
    display_name: Luminous Base (13B)
    description: Luminous Base (13B parameters) ([docs](https://docs.aleph-alpha.com/docs/introduction/luminous/))
    creator_organization_name: Aleph Alpha
    access: limited
    num_parameters: 13000000000
    # TODO: get exact release date
    release_date: 2022-01-01
    # Does not support echo
    tags: [TEXT_MODEL_TAG, IMAGE_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG]

  - name: AlephAlpha/luminous-extended
    display_name: Luminous Extended (30B)
    description: Luminous Extended (30B parameters) ([docs](https://docs.aleph-alpha.com/docs/introduction/luminous/))
    creator_organization_name: Aleph Alpha
    access: limited
    num_parameters: 30000000000
    release_date: 2022-01-01
    # Does not support echo
    tags: [TEXT_MODEL_TAG, IMAGE_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG]

  - name: AlephAlpha/luminous-supreme
    display_name: Luminous Supreme (70B)
    description: Luminous Supreme (70B parameters) ([docs](https://docs.aleph-alpha.com/docs/introduction/luminous/))
    creator_organization_name: Aleph Alpha
    access: limited
    num_parameters: 70000000000
    release_date: 2022-01-01
    # Does not support echo.
    # TODO: images will be supported in the near future. Add IMAGE_MODEL_TAG.
    tags: [TEXT_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG]
  
  # TODO: coming soon. Uncomment out the following when Luminous World is released.
  # - name: AlephAlpha/luminous-world
  #   display_name: Luminous World (178B)
  #   description: Luminous World (178B parameters) ([docs](https://docs.aleph-alpha.com/docs/introduction/luminous/))
  #   creator_organization_name: Aleph Alpha
  #   access: limited
  #   num_parameters: TBD
  #   release_date: TBD
  #   # Does not support echo.
  #   tags: [TEXT_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG]
  # =================================== #



  # =========== Anthropic =========== #
  - name: anthropic/claude-v1.3
    display_name: Anthropic Claude v1.3
    description: A 52B parameter language model, trained using reinforcement learning from human feedback [paper](https://arxiv.org/pdf/2204.05862.pdf).
    creator_organization_name: Anthropic
    access: limited
    num_parameters: 52000000000
    release_date: 2023-03-17
    tags: [ANTHROPIC_CLAUDE_1_MODEL_TAG, TEXT_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG, GPT2_TOKENIZER_TAG, ABLATION_MODEL_TAG, INSTRUCTION_FOLLOWING_MODEL_TAG]
 
  - name: anthropic/claude-instant-v1
    display_name: Anthropic Claude Instant V1
    description: A lightweight version of Claude, a model trained using reinforcement learning from human feedback ([docs](https://www.anthropic.com/index/introducing-claude)).
    creator_organization_name: Anthropic
    access: limited
    release_date: 2023-03-17
    tags: [ANTHROPIC_CLAUDE_1_MODEL_TAG, TEXT_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG, GPT2_TOKENIZER_TAG, ABLATION_MODEL_TAG, INSTRUCTION_FOLLOWING_MODEL_TAG]

  - name: anthropic/claude-2.0
    display_name: Anthropic Claude 2.0
    description: Claude 2.0 is a general purpose large language model developed by Anthropic. It uses a transformer architecture and is trained via unsupervised learning, RLHF, and Constitutional AI (including both a supervised and Reinforcement Learning (RL) phase). ([model card](https://efficient-manatee.files.svdcdn.com/production/images/Model-Card-Claude-2.pdf))
    creator_organization_name: Anthropic
    access: limited
    release_date: 2023-07-11
    tags: [ANTHROPIC_CLAUDE_2_MODEL_TAG, TEXT_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG, GPT2_TOKENIZER_TAG, ABLATION_MODEL_TAG, INSTRUCTION_FOLLOWING_MODEL_TAG]

  # DEPRECATED: Please do not use.
  - name: anthropic/stanford-online-all-v4-s3
    display_name: Anthropic-LM v4-s3 (52B)
    description: A 52B parameter language model, trained using reinforcement learning from human feedback [paper](https://arxiv.org/pdf/2204.05862.pdf).
    creator_organization_name: Anthropic
    access: closed
    num_parameters: 52000000000
    release_date: 2021-12-01
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, GPT2_TOKENIZER_TAG, ABLATION_MODEL_TAG]
  # ================================= #



  # =========== Berkeley =========== #
  - name: together/koala-13b
    display_name: Koala (13B)
    description: Koala (13B) is a chatbot fine-tuned from Llama (13B) on dialogue data gathered from the web. ([blog post](https://bair.berkeley.edu/blog/2023/04/03/koala/))
    creator_organization_name: UC Berkeley
    access: open
    num_parameters: 13000000000
    release_date: 2022-04-03
    tags: [] # TODO: add tags
  # ================================= #



  # =========== BigScience =========== #
  - name: together/bloom
    display_name: BLOOM (176B)
    description: BLOOM (176B parameters) is an autoregressive model trained on 46 natural languages and 13 programming languages ([paper](https://arxiv.org/pdf/2211.05100.pdf)).
    creator_organization_name: BigScience
    access: open
    num_parameters: 176000000000
    release_date: 2022-06-28
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, ABLATION_MODEL_TAG]

  - name: together/bloomz
    display_name: BLOOMZ (176B)
    description: BLOOMZ (176B parameters) is BLOOM that has been fine-tuned on natural language instructions ([details](https://huggingface.co/bigscience/bloomz)).
    creator_organization_name: BigScience
    access: open
    num_parameters: 176000000000
    release_date: 2022-11-03
    tags: [] # TODO: add tags

  - name: together/t0pp
    display_name: T0pp (11B)
    description: T0pp (11B parameters) is an encoder-decoder model trained on a large set of different tasks specified in natural language prompts ([paper](https://arxiv.org/pdf/2110.08207.pdf)).
    creator_organization_name: BigScience
    access: open
    num_parameters: 11000000000
    release_date: 2021-10-15
    # Does not support echo.
    tags: [TEXT_MODEL_TAG, LIMITED_FUNCTIONALITY_TEXT_MODEL_TAG, ABLATION_MODEL_TAG, NO_NEWLINES_TAG]
  # ================================== #



  # =========== BigCode =========== #
  - name: huggingface/santacoder
    display_name: SantaCoder (1.1B)
    description: SantaCoder (1.1B parameters) model trained on the Python, Java, and JavaScript subset of The Stack (v1.1) ([model card](https://huggingface.co/bigcode/santacoder)).
    creator_organization_name: BigCode
    access: open
    num_parameters: 1100000000
    release_date: 2023-01-09 # ArXiv submission date
    tags: [CODE_MODEL_TAG]

  - name: huggingface/starcoder
    display_name: StarCoder (15.5B)
    description: The StarCoder (15.5B parameter) model trained on 80+ programming languages from The Stack (v1.2) ([model card](https://huggingface.co/bigcode/starcoder)).
    creator_organization_name: BigCode
    access: open
    num_parameters: 15500000000
    release_date: 2023-05-09 # ArXiv submission date
    tags: [CODE_MODEL_TAG]
  # =============================== #



  # =========== Cerebras Systems =========== #
  - name: together/cerebras-gpt-6.7b
    display_name: Cerebras GPT (6.7B)
    description: Cerebras GPT is a family of open compute-optimal language models scaled from 111M to 13B parameters trained on the Eleuther Pile. ([paper](https://arxiv.org/pdf/2304.03208.pdf))
    creator_organization_name: Cerebras
    access: limited
    num_parameters: 6700000000
    release_date: 2023-04-06
    tags: [] # TODO: add tags

  - name: together/cerebras-gpt-13b
    display_name: Cerebras GPT (13B)
    description: Cerebras GPT is a family of open compute-optimal language models scaled from 111M to 13B parameters trained on the Eleuther Pile. ([paper](https://arxiv.org/pdf/2304.03208.pdf))
    creator_organization_name: Cerebras
    access: limited
    num_parameters: 13000000000
    release_date: 2023-04-06
    tags: [] # TODO: add tags
  # ======================================== #



  # =========== Cohere =========== #
  # Model versioning and the possible versions are not documented here:
  # https://docs.cohere.ai/generate-reference#model-optional.
  # So, instead, we got the names of the models from the Cohere Playground.
  #
  # Note that their tokenizer and model were trained on English text and
  # they do not have a dedicated decode API endpoint, so the adaptation
  # step for language modeling fails for certain Scenarios:
  # the_pile:subset=ArXiv
  # the_pile:subset=Github
  # the_pile:subset=PubMed Central
  - name: cohere/xlarge-20220609
    display_name: Cohere xlarge v20220609 (52.4B)
    description: Cohere xlarge v20220609 (52.4B parameters)
    creator_organization_name: Cohere
    access: limited
    num_parameters: 52400000000
    release_date: 2022-06-09
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG]

  - name: cohere/large-20220720
    display_name: Cohere large v20220720 (13.1B)
    description: Cohere large v20220720 (13.1B parameters), which is deprecated by Cohere as of December 2, 2022.
    creator_organization_name: Cohere
    access: limited
    num_parameters: 13100000000
    release_date: 2022-07-20
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG]

  - name: cohere/medium-20220720
    display_name: Cohere medium v20220720 (6.1B)
    description: Cohere medium v20220720 (6.1B parameters)
    creator_organization_name: Cohere
    access: limited
    num_parameters: 6100000000
    release_date: 2022-07-20
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG]

  - name: cohere/small-20220720
    display_name: Cohere small v20220720 (410M)
    description: Cohere small v20220720 (410M parameters), which is deprecated by Cohere as of December 2, 2022.
    creator_organization_name: Cohere
    access: limited
    num_parameters: 410000000
    release_date: 2022-07-20
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG]

  - name: cohere/xlarge-20221108
    display_name: Cohere xlarge v20221108 (52.4B)
    description: Cohere xlarge v20221108 (52.4B parameters)
    creator_organization_name: Cohere
    access: limited
    num_parameters: 52400000000
    release_date: 2022-11-08
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG]

  - name: cohere/medium-20221108
    display_name: Cohere medium v20221108 (6.1B)
    description: Cohere medium v20221108 (6.1B parameters)
    creator_organization_name: Cohere
    access: limited
    num_parameters: 6100000000
    release_date: 2022-11-08
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG]

  - name: cohere/command-medium-beta
    display_name: Cohere Command beta (6.1B)
    description: Cohere Command beta (6.1B parameters) is fine-tuned from the medium model to respond well with instruction-like prompts ([details](https://docs.cohere.ai/docs/command-beta)).
    creator_organization_name: Cohere
    access: limited
    num_parameters: 6100000000
    release_date: 2022-11-08
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG, INSTRUCTION_FOLLOWING_MODEL_TAG]

  - name: cohere/command-xlarge-beta
    display_name: Cohere Command beta (52.4B)
    description: Cohere Command beta (52.4B parameters) is fine-tuned from the XL model to respond well with instruction-like prompts ([details](https://docs.cohere.ai/docs/command-beta)).
    creator_organization_name: Cohere
    access: limited
    num_parameters: 52400000000
    release_date: 2022-11-08
    tags: [TEXT_MODEL_TAG, FULL_FUNCTIONALITY_TEXT_MODEL_TAG, COHERE_TOKENIZER_TAG, INSTRUCTION_FOLLOWING_MODEL_TAG]
  # ============================== #