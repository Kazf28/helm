{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4195eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram_path =  'pile_ngrams/output_stats_pi..gram_xaa_ngrams'\n",
    "scenario_path = './data/xaa'\n",
    "out_path = 'metrics_xaa'\n",
    "\n",
    "# Computing for N = 13 for illustrative purposes\n",
    "N = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8495368c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import json\n",
    "import cattrs\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from data_overlap_spec import DataOverlapStats, DataOverlapStatsKey, EntryOverlapNgrams\n",
    "from compute_data_overlap_metrics import load_light_scenarios_from_jsonl\n",
    "from common.util import get_tokenizer\n",
    "from common.general import asdict_without_nones\n",
    "\n",
    "from enum import Enum\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "682e5447",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@dataclass(frozen=True)\n",
    "class EntryDataOverlapKey:\n",
    "    \"\"\"Unique key representing either the input or references of a single instance in a scenario.\"\"\"\n",
    "\n",
    "    stats_key: DataOverlapStatsKey\n",
    "    part: str\n",
    "    \"\"\"Either PART_INPUT or PART_REF\"\"\"\n",
    "    instance_id: str\n",
    "\n",
    "\n",
    "# Input: List[EntryOverlapNgrams]\n",
    "@dataclass(frozen=True)\n",
    "class EntryOverlapNgrams:\n",
    "    \"\"\"Dataclass that represents output data overlap stats\"\"\"\n",
    "\n",
    "    entry_data_overlap_key: EntryDataOverlapKey\n",
    "\n",
    "    overlapping_ngram_counts: List[Tuple[str, int]]\n",
    "\n",
    "\n",
    "class PartialOverlapSpec(int, Enum):\n",
    "    binary = 0\n",
    "    jaccard = 1\n",
    "    token = 2\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class FrequencySpec:\n",
    "    # Filter ngrams with frequency >= filter_value; 0 means no filter\n",
    "    filter_value: int\n",
    "    # Whether to apply weight; we'll do inverse frequency\n",
    "    weighting: bool\n",
    "        \n",
    "@dataclass(frozen=True)\n",
    "class MetricProtocolSpec:\n",
    "    \"\"\"Specification for how we compute the metric\"\"\"\n",
    "    \n",
    "    partial_overlap_spec: PartialOverlapSpec\n",
    "    frequency_spec: FrequencySpec\n",
    "        \n",
    "@dataclass(frozen=True)\n",
    "class OverlapMetric:\n",
    "    metric_score: float # use 0/1 for binary, can revise as neded\n",
    "    metric_protocol_spec: MetricProtocolSpec\n",
    "\n",
    "# Output: List[EntryOverlapMetric]\n",
    "@dataclass(frozen=True)\n",
    "class EntryOverlapMetric:\n",
    "    \"\"\"Dataclass that represents output data overlap stats\"\"\"\n",
    "\n",
    "    entry_data_overlap_key: EntryDataOverlapKey\n",
    "\n",
    "    overlap_metric: OverlapMetric\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594e6d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Ngrams\n",
    "ngram_jsons = open(ngram_path, \"r\").readlines()\n",
    "entry_overlap_ngrams_list = []\n",
    "for ngram_json in ngram_jsons:\n",
    "    entry_overlap_ngrams = json.loads(ngram_json)\n",
    "    entry_overlap_ngrams_list.append(cattrs.structure(entry_overlap_ngrams, EntryOverlapNgrams))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc11f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create entry_overlap_ngrams_dict, a dict of DataOverlapStatsKey -> EntryOverlapNgrams\n",
    "entry_overlap_ngrams_dict = defaultdict(list)\n",
    "for entry_overlap_ngrams in entry_overlap_ngrams_list:\n",
    "    entry_data_overlap_key = entry_overlap_ngrams.entry_data_overlap_key\n",
    "    overlapping_ngram_counts = entry_overlap_ngrams.overlapping_ngram_counts\n",
    "    ngram_count = entry_data_overlap_key.stats_key.overlap_protocol_spec.n\n",
    "    stats_key = entry_data_overlap_key.stats_key\n",
    "    if ngram_count not in [N]:\n",
    "        continue\n",
    "    entry_overlap_ngrams_dict[stats_key].append(entry_overlap_ngrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c39db8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Scenarios\n",
    "light_scenarios = load_light_scenarios_from_jsonl(scenario_path)\n",
    "light_scenario_instance_dict = dict()\n",
    "for light_scenario in light_scenarios:\n",
    "    instances = light_scenario.instances\n",
    "    instance_dict = dict()\n",
    "    for instance in instances:\n",
    "        instance_dict[instance.id] = instance\n",
    "    light_scenario_instance_dict[light_scenario.scenario_key] = instance_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "808b1f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def compute_binary_overlap(instance_str, overlapping_ngram_counts, tokenizer, frequency = 0):\n",
    "    \"\"\" \n",
    "    Compute  binary overlap\n",
    "    If pass in frequency, include only the ngrams with count <= frequency\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(instance_str)\n",
    "    ngram_counts_dict = defaultdict(int)\n",
    "    \n",
    "    # construct a dict of ngram -> count\n",
    "    for ngram, count in overlapping_ngram_counts:\n",
    "        ngram = tuple(ast.literal_eval(ngram))\n",
    "        ngram_counts_dict[ngram] = count\n",
    "\n",
    "    metric_score = 0\n",
    "\n",
    "    for ngram in ngrams(tokens, N):\n",
    "        count = ngram_counts_dict[ngram]\n",
    "        if frequency == 0 or count <= frequency:\n",
    "            if count != 0:\n",
    "                metric_score = 1\n",
    "                break\n",
    "\n",
    "    overlap_metric = OverlapMetric(\n",
    "        metric_score = metric_score,\n",
    "        metric_protocol_spec = MetricProtocolSpec(\n",
    "            partial_overlap_spec = PartialOverlapSpec.jaccard,\n",
    "            frequency_spec = FrequencySpec(\n",
    "                filter_value = frequency,\n",
    "                weighting = False\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return overlap_metric\n",
    "\n",
    "def compute_jaccard_overlap(instance_str, overlapping_ngram_counts, tokenizer, frequency = 0):\n",
    "    \"\"\" \n",
    "    Compute weighted and unweighted jaccard overlap\n",
    "    If pass in frequency, include only the ngrams with count <= frequency\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(instance_str)\n",
    "    ngram_counts_dict = defaultdict(int)\n",
    "    \n",
    "    # construct a dict of ngram -> count\n",
    "    for ngram, count in overlapping_ngram_counts:\n",
    "        ngram = tuple(ast.literal_eval(ngram))\n",
    "        ngram_counts_dict[ngram] = count\n",
    "\n",
    "    total_ngram_count = 0\n",
    "    counts = 0\n",
    "    weighted_score = 0\n",
    "\n",
    "    for ngram in ngrams(tokens, N):\n",
    "        count = ngram_counts_dict[ngram]\n",
    "        if frequency == 0 or count <= frequency:\n",
    "            if count != 0:\n",
    "                counts += 1\n",
    "                weighted_score += 1 / count\n",
    "        total_ngram_count += 1\n",
    "\n",
    "    unweighted_score = counts / total_ngram_count\n",
    "    weighted_score = weighted_score / total_ngram_count\n",
    "\n",
    "    unweighted_overlap_metric = OverlapMetric(\n",
    "        metric_score = unweighted_score ,\n",
    "        metric_protocol_spec = MetricProtocolSpec(\n",
    "            partial_overlap_spec = PartialOverlapSpec.jaccard,\n",
    "            frequency_spec = FrequencySpec(\n",
    "                filter_value = frequency,\n",
    "                weighting = False\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    weighted_overlap_metric = OverlapMetric(\n",
    "        metric_score = weighted_score ,\n",
    "        metric_protocol_spec = MetricProtocolSpec(\n",
    "            partial_overlap_spec = PartialOverlapSpec.jaccard,\n",
    "            frequency_spec = FrequencySpec(\n",
    "                filter_value = frequency,\n",
    "                weighting = True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return unweighted_overlap_metric, weighted_overlap_metric\n",
    "\n",
    "# Token overlap\n",
    "def compute_token_overlap(instance_str, overlapping_ngram_counts, tokenizer, frequency = 0):\n",
    "    \"\"\" \n",
    "    Compute weighted and unweighted token overlap\n",
    "    If pass in frequency, include only the ngrams with count <= frequency\n",
    "    \"\"\"\n",
    "    tokens = tokenizer.tokenize(instance_str)\n",
    "    ngram_counts_dict = defaultdict(int)\n",
    "    \n",
    "    # construct a dict of ngram -> count\n",
    "    for ngram, count in overlapping_ngram_counts:\n",
    "        ngram = tuple(ast.literal_eval(ngram))\n",
    "        ngram_counts_dict[ngram] = count\n",
    "\n",
    "    total_token_count = 0\n",
    "    counts = 0\n",
    "    weighted_score = 0\n",
    "    weight = 0\n",
    "    token_budget = 0\n",
    "\n",
    "    for ngram in ngrams(tokens, N):\n",
    "        curr_count = ngram_counts_dict[ngram]\n",
    "        if frequency == 0 or count <= frequency:\n",
    "            if curr_count != 0:\n",
    "                token_budget = N\n",
    "                if weight > 0:\n",
    "                    weight = min(curr_count, weight)\n",
    "                else:\n",
    "                    weight = curr_count \n",
    "\n",
    "        if token_budget > 0:\n",
    "            token_budget -= 1\n",
    "            counts += 1\n",
    "            weighted_score += 1 / weight\n",
    "        else:\n",
    "            weight = 0\n",
    "        total_token_count += 1\n",
    "\n",
    "    for token in ngram[1:]:\n",
    "        if token_budget > 0:\n",
    "            token_budget -= 1\n",
    "            counts += 1\n",
    "            weighted_score += 1 / weight\n",
    "        total_token_count += 1\n",
    "\n",
    "    unweighted_score = counts / total_token_count\n",
    "    weighted_score = weighted_score / total_token_count\n",
    "\n",
    "    unweighted_overlap_metric = OverlapMetric(\n",
    "        metric_score = unweighted_score ,\n",
    "        metric_protocol_spec = MetricProtocolSpec(\n",
    "            partial_overlap_spec = PartialOverlapSpec.token,\n",
    "            frequency_spec = FrequencySpec(\n",
    "                filter_value = frequency,\n",
    "                weighting = False\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    weighted_overlap_metric = OverlapMetric(\n",
    "        metric_score = weighted_score ,\n",
    "        metric_protocol_spec = MetricProtocolSpec(\n",
    "            partial_overlap_spec = PartialOverlapSpec.token,\n",
    "            frequency_spec = FrequencySpec(\n",
    "                filter_value = frequency,\n",
    "                weighting = True\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return unweighted_overlap_metric, weighted_overlap_metric\n",
    "\n",
    "def compute_and_add_metrics(instance_str, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, frequency = 0):\n",
    "\n",
    "    overlap_metric = compute_binary_overlap(instance_str, overlapping_ngram_counts, tokenizer, frequency)\n",
    "    binary_metric = EntryOverlapMetric(entry_data_overlap_key=entry_data_overlap_key, overlap_metric=overlap_metric)\n",
    "    entry_overlap_metric_list.append(binary_metric)\n",
    "\n",
    "    unweighted_overlap_metric, weighted_overlap_metric = compute_jaccard_overlap(instance_str, overlapping_ngram_counts, tokenizer, frequency)\n",
    "    unweighted_jaccard = EntryOverlapMetric(entry_data_overlap_key=entry_data_overlap_key, overlap_metric=unweighted_overlap_metric)\n",
    "    weighted_jaccard = EntryOverlapMetric(entry_data_overlap_key=entry_data_overlap_key, overlap_metric=weighted_overlap_metric)\n",
    "    entry_overlap_metric_list.append(unweighted_jaccard)\n",
    "    entry_overlap_metric_list.append(weighted_jaccard)\n",
    "\n",
    "    unweighted_overlap_metric, weighted_overlap_metric = compute_token_overlap(instance_str, overlapping_ngram_counts, tokenizer, frequency)\n",
    "    unweighted_token = EntryOverlapMetric(entry_data_overlap_key=entry_data_overlap_key, overlap_metric=unweighted_overlap_metric)\n",
    "    weighted_token = EntryOverlapMetric(entry_data_overlap_key=entry_data_overlap_key, overlap_metric=weighted_overlap_metric)\n",
    "    entry_overlap_metric_list.append(unweighted_token)\n",
    "    entry_overlap_metric_list.append(weighted_token)\n",
    "\n",
    "def save_metrics_to_jsonl(overlap_metrics: List[EntryOverlapMetric], filename: str):\n",
    "    with open(filename, \"w\") as f:\n",
    "        for overlap_metric in overlap_metrics:\n",
    "            f.write(json.dumps(asdict_without_nones(overlap_metric), ensure_ascii=False) + \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e84da9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entry_overlap_metric_list = []\n",
    "tokenizer = get_tokenizer('default')\n",
    "for data_overlap_stats_key, entry_overlap_ngrams_list in entry_overlap_ngrams_dict.items():\n",
    "    light_scenario_key = data_overlap_stats_key.light_scenario_key\n",
    "    instance_dict = light_scenario_instance_dict[light_scenario_key]\n",
    "    for entry_overlap_ngrams in entry_overlap_ngrams_list:\n",
    "        entry_data_overlap_key = entry_overlap_ngrams.entry_data_overlap_key\n",
    "        instance_id = entry_data_overlap_key.instance_id\n",
    "        instance = instance_dict[instance_id]\n",
    "        part = entry_data_overlap_key.part\n",
    "        overlapping_ngram_counts = entry_overlap_ngrams.overlapping_ngram_counts\n",
    "        if part == 'input':\n",
    "            compute_and_add_metrics(instance.input, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list)\n",
    "            compute_and_add_metrics(instance.input, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, frequency=10)\n",
    "        if part == 'references':\n",
    "            reference = ' '.join(instance.references)\n",
    "            compute_and_add_metrics(reference, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list)\n",
    "            compute_and_add_metrics(reference, overlapping_ngram_counts, tokenizer, entry_data_overlap_key, entry_overlap_metric_list, frequency=10)\n",
    "\n",
    "save_metrics_to_jsonl(entry_overlap_metric_list, out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
