[
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=anthropic_claude-3-haiku-20240307",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "Answer with only a single letter.\n\nThe following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "anthropic/claude-3-haiku-20240307",
      "model": "anthropic/claude-3-haiku-20240307",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=anthropic_claude-3-opus-20240229",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "Answer with only a single letter.\n\nThe following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "anthropic/claude-3-opus-20240229",
      "model": "anthropic/claude-3-opus-20240229",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=anthropic_claude-3-sonnet-20240229",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "Answer with only a single letter.\n\nThe following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "anthropic/claude-3-sonnet-20240229",
      "model": "anthropic/claude-3-sonnet-20240229",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=google_gemini-1.0-pro-001",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "google/gemini-1.0-pro-001",
      "model": "google/gemini-1.0-pro-001",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=google_gemini-1.5-pro-preview-0409",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "google/gemini-1.5-pro-preview-0409",
      "model": "google/gemini-1.5-pro-preview-0409",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=meta_llama-3-70b",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "together/llama-3-70b",
      "model": "meta/llama-3-70b",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=meta_llama-3-8b",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "together/llama-3-8b",
      "model": "meta/llama-3-8b",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=mistralai_mixtral-8x22b",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "together/mixtral-8x22b",
      "model": "mistralai/mixtral-8x22b",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=openai_gpt-4-0125-preview",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "openai/gpt-4-0125-preview",
      "model": "openai/gpt-4-0125-preview",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=openai_gpt-4-turbo-2024-04-09",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 1,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "openai/gpt-4-turbo-2024-04-09",
      "model": "openai/gpt-4-turbo-2024-04-09",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  },
  {
    "name": "bbq:subject=all,method=multiple_choice_joint,model=writer_palmyra-x-v2",
    "scenario_spec": {
      "class_name": "helm.benchmark.scenarios.bbq_scenario.BBQScenario",
      "args": {
        "subject": "all"
      }
    },
    "adapter_spec": {
      "method": "multiple_choice_joint",
      "global_prefix": "",
      "global_suffix": "",
      "instructions": "The following are multiple choice questions (with answers).\n",
      "input_prefix": "Passage: ",
      "input_suffix": "\n",
      "reference_prefix": "A. ",
      "reference_suffix": "\n",
      "output_prefix": "Answer: ",
      "output_suffix": "\n",
      "instance_prefix": "\n",
      "substitutions": [],
      "max_train_instances": 5,
      "max_eval_instances": 50,
      "num_outputs": 5,
      "num_train_trials": 1,
      "num_trials": 1,
      "sample_train": true,
      "model_deployment": "writer/palmyra-x-v2",
      "model": "writer/palmyra-x-v2",
      "temperature": 0.0,
      "max_tokens": 1,
      "stop_sequences": [
        "\n"
      ],
      "multi_label": false
    },
    "metric_specs": [
      {
        "class_name": "helm.benchmark.metrics.bbq_metrics.BBQMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicGenerationMetric",
        "args": {
          "names": [
            "exact_match",
            "quasi_exact_match",
            "prefix_exact_match",
            "quasi_prefix_exact_match"
          ]
        }
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.BasicReferenceMetric",
        "args": {}
      },
      {
        "class_name": "helm.benchmark.metrics.basic_metrics.InstancesPerSplitMetric",
        "args": {}
      }
    ],
    "data_augmenter_spec": {
      "perturbation_specs": [],
      "should_augment_train_instances": false,
      "should_include_original_train": false,
      "should_skip_unchanged_train": false,
      "should_augment_eval_instances": false,
      "should_include_original_eval": false,
      "should_skip_unchanged_eval": false,
      "seeds_per_instance": 1
    },
    "groups": [
      "bbq"
    ]
  }
]