\begin{table*}[htp]
\resizebox{\textwidth}{!}{
\begin{tabular}{lrr}
\toprule
Model/adapter & Mean win rate & BBQ - Observed inference time (s) \\
\midrule
Llama 3 (70B) & 0.9 & 0.4727405834197998 \\
Llama 3 (8B) & 1.0 & 0.3197813606262207 \\
Mixtral (8x22B) & 0.7 & 0.634566559791565 \\
Claude 3 Haiku (20240307) & 0.5 & 0.7083269453048706 \\
Claude 3 Sonnet (20240229) & 0.2 & 1.0551340627670287 \\
Claude 3 Opus (20240229) &  & 1.5528087568283082 \\
Gemini 1.0 Pro (001) & 0.3 & 0.918980827331543 \\
Gemini 1.5 Pro (0409 preview) & 0.6 & 0.6445135402679444 \\
GPT-4 Turbo (0125 preview) & 0.4 & 0.9111762857437133 \\
GPT-4 Turbo (2024-04-09) & 0.1 & 1.3869879245758057 \\
Palmyra X V2 (33B) & 0.8 & 0.5032276248931885 \\
\bottomrule
\end{tabular}}
\caption{Results for efficiency_detailed (targeted_evaluations)}
\label{fig:efficiency_detailed (targeted_evaluations)}
\end{table*}